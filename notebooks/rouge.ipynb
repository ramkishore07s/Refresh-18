{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import itertools\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge as RougeComputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer(PorterStemmer.ORIGINAL_ALGORITHM)\n",
    "stem_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_word(word):\n",
    "    if word not in stem_cache:\n",
    "        try:\n",
    "            stem_cache[word] = stemmer.stem(word)\n",
    "        except:\n",
    "            stem_cache[word] = word\n",
    "    return stem_cache[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeRouge(folder1, folder2):\n",
    "    # rouge_args=\"-e /home/ramkishore.s/ROUGE-1.5.5/data/ -a -c 95 -m -n 2 -w 1.2\"   \n",
    "    from pyrouge import Rouge155\n",
    "    r = Rouge155()\n",
    "    r.system_dir = folder1\n",
    "    r.model_dir = folder2\n",
    "    r.system_filename_pattern = '(\\d+)'\n",
    "    r.model_filename_pattern = '#ID#'\n",
    "\n",
<<<<<<< HEAD
    "    output = r.convert_and_evaluate(rouge_args=\"-e /home/ramkishore.s/ROUGE-1.5.5/data/ -a -c 95 -m -n 2 -w 1.2\")\n",
=======
    "    output = r.convert_and_evaluate()#rouge_args=\"-e /home/ramkishore.s/ROUGE-1.5.5/data/ -a -c 95 -m -n 2 -w 1.2\")\n",
>>>>>>> 14ba256f457a7ef567dfb2011af64a82a4e13fb4
    "    output = r.output_to_dict(output)\n",
    "    return [output['rouge_1_f_score'], output['rouge_2_f_score'], output['rouge_l_f_score']], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_lcs(a, b, stemming=True):\n",
    "    '''\n",
    "    returns length of lcs of a and b\n",
    "    a, b are lists of tokens\n",
    "    _get_lcs(['a','b','c'], ['a', 'b', 'c', 'd']) returns 3\n",
    "    '''\n",
    "    if stemming:\n",
    "        a = [stem_word(word) for word in a]\n",
    "        b = [stem_word(word) for word in b]\n",
    "    \n",
    "    lengths = [[0 for j in range(len(b)+1)] for i in range(len(a)+1)]\n",
    "    # row 0 and column 0 are initialized to 0 already\n",
    "    for i, x in enumerate(a):\n",
    "        for j, y in enumerate(b):\n",
    "            if x == y:\n",
    "                lengths[i+1][j+1] = lengths[i][j] + 1\n",
    "            else:\n",
    "                lengths[i+1][j+1] = max(lengths[i+1][j], lengths[i][j+1])\n",
    "    # read the substring out from the matrix\n",
    "    result = []\n",
    "    x, y = len(a), len(b)\n",
    "    while x != 0 and y != 0:\n",
    "        if lengths[x][y] == lengths[x-1][y]:\n",
    "            x -= 1\n",
    "        elif lengths[x][y] == lengths[x][y-1]:\n",
    "            y -= 1\n",
    "        else:\n",
    "            assert a[x-1] == b[y-1]\n",
    "            result = [a[x-1]] + result\n",
    "            x -= 1\n",
    "            y -= 1\n",
    "    return len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_ngram_sets(highlights, stemming=True):\n",
    "    '''\n",
    "    get n_gram sets of length 1, 2, 3, 4\n",
    "    \n",
    "    _get_ngram_sets(['a', 'b', 'c', 'd']) returns:\n",
    "    \n",
    "    ({'a', 'b', 'c', 'd'}, \n",
    "     {'a-b', 'b-c', 'c-d'}, \n",
    "     {'a-b-c', 'b-c-d'}, \n",
    "     {'a-b-c-d'}\n",
    "    )\n",
    "    '''\n",
    "    if stemming:\n",
    "        highlights = [stem_word(word) for word in highlights]\n",
    "        \n",
    "    set_1gram = set()\n",
    "    set_2gram = set()\n",
    "    set_3gram = set()\n",
    "    set_4gram = set()\n",
    "    fullen = len(highlights)\n",
    "    for widx in range(fullen):\n",
    "        # 1gram\n",
    "        set_1gram.add(str(highlights[widx]))\n",
    "        # 2gram\n",
    "        if (widx+1) < fullen:\n",
    "            set_2gram.add(str(highlights[widx])+\"-\"+str(highlights[widx+1]))\n",
    "        # 3gram\n",
    "        if (widx+2) < fullen:\n",
    "            set_3gram.add(str(highlights[widx])+\"-\"+str(highlights[widx+1])+\"-\"+str(highlights[widx+2]))\n",
    "        # 4gram\n",
    "        if (widx+3) < fullen:\n",
    "            set_4gram.add(str(highlights[widx])+\"-\"+str(highlights[widx+1])+\"-\"+str(highlights[widx+2])+\"-\"+str(highlights[widx+3]))\n",
    "    return set_1gram, set_2gram, set_3gram, set_4gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _rouge_wrapper_traindata_nopyrouge(final_labels_str, document, highlights):\n",
    "    '''\n",
    "    final_labels_str: an array of selected sentences' indices\n",
    "    document: array of array of words\n",
    "    highlights: array of array of words\n",
    "    \n",
    "    0 is used to represent end of sentence\n",
    "    \n",
    "    returns rouge recall average.\n",
    "    NOTE: recall increases with increase in summary length, so also consider using precision\n",
    "    '''\n",
    "    cand_highlights_full = []\n",
    "    for sentidx in final_labels_str:\n",
    "        cand_highlights_full += [wordid for wordid in document[int(sentidx)] if wordid != 0]\n",
    "        cand_highlights_full.append(0)\n",
    "    highlights_full = []\n",
    "    for sent in highlights:\n",
    "        highlights_full += sent\n",
    "        highlights_full.append(0)\n",
    "    # print(cand_highlights_full,highlights_full)\n",
    "       \n",
    "    # Get sets\n",
    "    cand_1gram, cand_2gram, cand_3gram, cand_4gram = _get_ngram_sets(cand_highlights_full)\n",
    "    # print(cand_1gram, cand_2gram, cand_3gram, cand_4gram)\n",
    "    gold_1gram, gold_2gram, gold_3gram, gold_4gram = _get_ngram_sets(highlights_full)\n",
    "    # print(gold_1gram, gold_2gram, gold_3gram, gold_4gram)\n",
    "    \n",
    "    # Get ROUGE-N recalls\n",
    "    rouge_recall_1 = 0\n",
    "    if len(gold_1gram) != 0:\n",
    "        rouge_recall_1 = float(len(gold_1gram.intersection(cand_1gram)))/float(len(gold_1gram))\n",
    "    rouge_recall_2 = 0\n",
    "    if len(gold_2gram) != 0:\n",
    "        rouge_recall_2 = float(len(gold_2gram.intersection(cand_2gram)))/float(len(gold_2gram))\n",
    "    rouge_recall_3 = 0\n",
    "    if len(gold_3gram) != 0:\n",
    "        rouge_recall_3 = float(len(gold_3gram.intersection(cand_3gram)))/float(len(gold_3gram))\n",
    "    rouge_recall_4 = 0\n",
    "    if len(gold_4gram) != 0:\n",
    "        rouge_recall_4 = float(len(gold_4gram.intersection(cand_4gram)))/float(len(gold_4gram))\n",
    "    \n",
    "    # Get ROUGE-L\n",
    "    len_lcs = _get_lcs(cand_highlights_full, highlights_full)\n",
    "    r = 0 if (len_lcs == 0) else (float(len_lcs)/len(cand_highlights_full))\n",
    "    p = 0 if (len_lcs == 0) else (float(len_lcs)/len(highlights_full))\n",
    "    b = 0 if (r == 0) else (p / r)\n",
    "    rouge_recall_l = 0 if (len_lcs == 0) else (((1+(b*b))*r*p)/(r+(b*b*p)))\n",
    "    \n",
    "    rouge_recall_average = (rouge_recall_1+rouge_recall_2+rouge_recall_3+rouge_recall_4+rouge_recall_l)/5.0\n",
    "    # print(rouge_recall_1, rouge_recall_2, rouge_recall_3, rouge_recall_4, rouge_recall_l, rouge_recall_average)\n",
    "    \n",
    "    # Get final labels\n",
    "    final_labels = [[1, 0] if (str(sentidx) in final_labels_str.split(\"-\")) else [0, 1] for sentidx in range(90)]  # [max_doc_length, target_label_size]\n",
    "    \n",
    "    return rouge_recall_average, final_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
