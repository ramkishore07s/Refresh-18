{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import itertools\n",
    "import _pickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run paths.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeRouge(folder1, folder2):\n",
    "    # rouge_args=\"-e /home/ramkishore.s/ROUGE-1.5.5/data/ -a -c 95 -m -n 2 -w 1.2\"\n",
    "    from pyrouge import Rouge155\n",
    "    r = Rouge155()\n",
    "    r.system_dir = folder1\n",
    "    r.model_dir = folder2\n",
    "    r.system_filename_pattern = '(\\d+)'\n",
    "    r.model_filename_pattern = '#ID#'\n",
    "\n",
    "    output = r.convert_and_evaluate()\n",
    "    output = r.output_to_dict(output)\n",
    "    return [output['rouge_1_f_score_ce'], output['rouge_2_f_score_ce'], output['rouge_l_f_score_ce']], output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Rouge:\n",
    "    '''\n",
    "    class for computing rouge\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.stemmed_words = {}\n",
    "        self.stemmer = PorterStemmer().stem\n",
    "    \n",
    "    def get_stem(self, word):\n",
    "        if word not in self.stemmed_words:\n",
    "            try: self.stemmed_words[word] = self.stemmer(word)\n",
    "            except: self.stemmed_words[word] = word\n",
    "        word = self.stemmed_words[word]\n",
    "        return word\n",
    "    \n",
    "    def R1(self, pred, act, remove_stop=False, stem=False):\n",
    "        pred_dict, total = {}, 0\n",
    "        for word in pred:\n",
    "            if len(word) > 1 or word.isalpha():\n",
    "                if stem: word = self.get_stem(word)\n",
    "                if word not in pred_dict: pred_dict[word] = 0\n",
    "                pred_dict[word] += 1\n",
    "                total += 1\n",
    "            \n",
    "        words_matched = 0\n",
    "        words_unmatched = 0\n",
    "        for word in act:\n",
    "            if stem: word = self.get_stem(word)\n",
    "            if len(word) > 1 or word.isalpha():\n",
    "                if word in pred_dict and pred_dict[word] > 0:\n",
    "                    words_matched += 1\n",
    "                    pred_dict[word] -= 1\n",
    "                else: \n",
    "                    words_unmatched += 1\n",
    "        precision = words_matched / len(pred)\n",
    "        recall = words_matched / len(act)\n",
    "        try: f1 = 2 * precision * recall / (precision + recall)\n",
    "        except: f1 = 0.\n",
    "        \n",
    "        return f1\n",
    "\n",
    "    def R2(self, pred, act, remove_stop=False, stem=False):\n",
    "        pass\n",
    "\n",
    "    def Rl(self, pred, act, remove_stop=False, stem=False):\n",
    "        pass\n",
    "    \n",
    "    def compute_rouge(self, predicted_summary, actual_summary, r1_=True, r2_=False, rl_=False, remove_stop=False, stem=True, sum_=True):\n",
    "        '''\n",
    "        predicted_summary: list of sentences\n",
    "        actual_summary: list of sentences\n",
    "        rl is not implemented\n",
    "        '''\n",
    "        pred_words = np.hstack([line.split() for line in predicted_summary])\n",
    "        actual_words = np.hstack([line.split() for line in actual_summary])\n",
    "        scores = []\n",
    "        if r1_: scores.append(self.R1(pred_words, actual_words, remove_stop, stem))\n",
    "        if r2_: scores.append(self.R2(pred_words, actual_words, remove_stop, stem))\n",
    "        if rl_: scores.append(self.Rl(pred_words, actual_words, remove_stop, stem))\n",
    "            \n",
    "        if sum_:\n",
    "            scores = sum(scores)\n",
    "        \n",
    "        return scores\n",
    "    \n",
    "    def eval_folder(self, pred_folder, gold_folder):\n",
    "        pred_files = os.listdir(pred_folder)\n",
    "        scores = 0\n",
    "        for filename in pred_files:\n",
    "            pred_summary = open(pred_folder + filename).readlines()[1:]\n",
    "            actual_summary = open(gold_folder + filename).readlines()\n",
    "            scores += self.compute_rouge(pred_summary, actual_summary)\n",
    "        return scores / len(pred_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RougeNeuralSum(Rouge):\n",
    "    '''\n",
    "    Class for creating cache data of rouge scores\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(RougeNeuralSum, self).__init__()\n",
    "        self.lines_selected = []\n",
    "        self.summary_scores = []\n",
    "        self.scores = []\n",
    "    \n",
    "    \n",
    "    def computeLineScores(self, document_folder, summary_folder, docs, no_lines):\n",
    "        '''\n",
    "        k => no of top summaries to store\n",
    "        output: list of lists\n",
    "        scores are stored in a list of lists\n",
    "        dim[0] = document id\n",
    "        dim[1] = (sentences no. in tuple, corresponding score)\n",
    "        '''\n",
    "        self.lines_selected = []\n",
    "        for filename in docs:\n",
    "            print(str(docs.index(filename)) + '    ', end='\\r')\n",
    "            scores = []\n",
    "            summary = open(summary_folder + filename).readlines()\n",
    "            lines = open(document_folder + filename).readlines()[0:CONFIG.MAX_DOC_LEN]\n",
    "            for line in lines:\n",
    "                scores.append(self.compute_rouge([line], summary))\n",
    "            lines_selected = list(zip(*sorted(zip(range(len(scores)), scores), key=lambda x: x[1], reverse=True)[0:no_lines]))[0]\n",
    "            self.lines_selected.append(sorted(lines_selected))\n",
    "    \n",
    "    def computeRefreshScores(self, document_folder, summary_folder,  no_lines=10, no_summaries=10, len_summary=3):\n",
    "        docs = sorted(os.listdir(document_folder), key=lambda x: int(x))\n",
    "        self.summary_scores = [None for _ in range(len(docs))]\n",
    "        self.computeLineScores(document_folder, summary_folder, docs, no_lines)\n",
    "        \n",
    "        for filename, lines_sel in zip(docs, self.lines_selected):\n",
    "            print(str(docs.index(filename)) + '     ', end='\\r')\n",
    "            try:\n",
    "                lines = open(document_folder + filename).readlines()\n",
    "                actual_summary = open(summary_folder + filename).readlines()\n",
    "\n",
    "                possible_summaries = list(itertools.combinations(lines_sel, len_summary))\n",
    "                summary_scores = []\n",
    "\n",
    "                for psummary in possible_summaries:\n",
    "                    summary_lines = [lines[i] for i in psummary]\n",
    "                    summary_scores.append(self.compute_rouge(summary_lines, actual_summary))\n",
    "\n",
    "                summaries_selected = sorted(zip(possible_summaries, summary_scores), key=lambda x: x[1], reverse=True)[0:no_summaries]\n",
    "                self.summary_scores[int(filename)] = summaries_selected\n",
    "            except:\n",
    "                self.summary_scores[int(filename)] = None\n",
    "            \n",
    "    def dump(self, filename):\n",
    "        pickle.dump(self.summary_scores, open(filename, 'wb+'))\n",
    "    \n",
    "    def load(self, filename):\n",
    "        self.summary_scores = pickle.load(open(filename, 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "refresh",
   "language": "python",
   "name": "refresh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
