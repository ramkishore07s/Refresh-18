{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run rouge.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge as RougeComputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_label_generator(documents_folder, summary_folder, output_dump, max_sentences=20):\n",
    "    '''\n",
    "    This code is a simpler version of actual greedy summary generator\n",
    "    TODO: code up actual greedy label generator\n",
    "    '''\n",
    "    rouge = RougeComputer()\n",
    "    output = []\n",
    "    filenames = sorted(os.listdir(documents_folder), key=lambda x: int(x))\n",
    "    for filename in filenames:\n",
    "        summary = open(os.path.join(summary_folder, filename)).read().replace('\\n', ' \\n')\n",
    "        doc_lines = open(os.path.join(documents_folder, filename)).readlines()\n",
    "        \n",
    "        selected_lines = []\n",
    "        prev_score = 0\n",
    "        for no, line in zip(range(len(doc_lines[0:max_sentences])), doc_lines[0:max_sentences]):\n",
    "            prev_summary = \"\"\n",
    "            for line_ in selected_lines:\n",
    "                prev_summary += doc_lines[line_] + ' '\n",
    "            selected_summary = prev_summary + ' ' + line\n",
    "            scores = rouge.get_scores(selected_summary, summary, avg=True)\n",
    "            avg_score = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f'])/3\n",
    "            \n",
    "            if avg_score > prev_score:\n",
    "                selected_lines.append(no)\n",
    "                prev_score = avg_score\n",
    "        output.append(selected_lines)\n",
    "        print(filename, end='\\r')\n",
    "    pickle.dump(output, open(output_dump, 'wb+'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_k_sentences(document, summary, max_select, f1=True, max_doc_len=90):\n",
    "    '''\n",
    "    document & summary: array of array of words\n",
    "    returns top max_select sentences with highest average rouge scores\n",
    "    '''\n",
    "    scores = []\n",
    "    \n",
    "    gold = []\n",
    "    for line in summary:\n",
    "        gold += line\n",
    "        gold.append(0)\n",
    "        \n",
    "    gold_1gram, gold_2gram, gold_3gram, gold_4gram = _get_ngram_sets(gold)\n",
    "    \n",
    "    for line in document[:max_doc_len]:\n",
    "        cand_1gram, cand_2gram, cand_3gram, cand_4gram = _get_ngram_sets(line)\n",
    " \n",
    "        rouge_recall_1 = 0\n",
    "        if len(gold_1gram) != 0:\n",
    "            rouge_recall_1 = float(len(gold_1gram.intersection(cand_1gram)))/float(len(gold_1gram))\n",
    "            \n",
    "        rouge_precision_1 = 0\n",
    "        if len(cand_1gram) != 0:\n",
    "            rouge_precision_1 = float(len(gold_1gram.intersection(cand_1gram)))/float(len(cand_1gram))\n",
    "            \n",
    "        rouge_f1_1 = 2 * rouge_recall_1 * rouge_precision_1 / (rouge_recall_1 + rouge_precision_1 + 10e-10)\n",
    "        \n",
    "        rouge_recall_2 = 0\n",
    "        if len(gold_2gram) != 0:\n",
    "            rouge_recall_2 = float(len(gold_2gram.intersection(cand_2gram)))/float(len(gold_2gram))\n",
    "        \n",
    "        rouge_precision_2 = 0\n",
    "        if len(cand_2gram) != 0:\n",
    "            rouge_precision_2 = float(len(gold_2gram.intersection(cand_2gram)))/float(len(cand_2gram))\n",
    "\n",
    "        rouge_f1_2 = 2 * rouge_recall_2 * rouge_precision_2 / (rouge_recall_2 + rouge_precision_2 + 10e-10)\n",
    "        \n",
    "        len_lcs = _get_lcs(line, gold)\n",
    "        r = 0 if (len_lcs == 0) else (float(len_lcs)/len(line))\n",
    "        p = 0 if (len_lcs == 0) else (float(len_lcs)/len(gold))\n",
    "        b = 0 if (r == 0) else (p / r)\n",
    "        rouge_recall_l = 0 if (len_lcs == 0) else (((1+(b*b))*r*p)/(r+(b*b*p)))\n",
    "        \n",
    "        rouge_f1_l = 2 * r * p / (r + p + 10e-10)\n",
    "        \n",
    "        rouge_recall_average = (rouge_recall_1+rouge_recall_2+rouge_recall_l)/3.0\n",
    "        rouge_f1_avg = (rouge_f1_1 + rouge_f1_2 + rouge_f1_l)/3.0\n",
    "        if f1: scores.append(rouge_f1_avg)\n",
    "        else: scores.append(rouge_recall_average)\n",
    "\n",
    "\n",
    "            \n",
    "    sorted_lines = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[0:max_select]\n",
    "    selected_lines = list(zip(*sorted_lines))[0]\n",
    "    \n",
    "    return sorted(selected_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_candidate_summaries(combinations, document, summary, lines_selected, max_sum_len=3, max_sum_select=15, f1=True):\n",
    "    '''\n",
    "    returns top max_sum_select summaries based on avg of ROUGE-1, ROUGE-2, ROUGE-L F1 scores\n",
    "    '''\n",
    "    scores = []\n",
    "    \n",
    "    gold = []\n",
    "    for line in summary:\n",
    "        gold += line\n",
    "        gold.append(0)\n",
    "        \n",
    "    gold_1gram, gold_2gram, gold_3gram, gold_4gram = _get_ngram_sets(gold)\n",
    "\n",
    "    # prepare candidate summaries\n",
    "    length = min(10, len(lines_selected))\n",
    "    candidates = []\n",
    "    \n",
    "    for i in range(max_sum_len + 1):\n",
    "        candidates += combinations[length][i]\n",
    "   \n",
    "    \n",
    "    for indices in candidates:\n",
    "        candidate_summary = []\n",
    "        for index in indices:\n",
    "            candidate_summary += document[lines_selected[index]]\n",
    "            candidate_summary.append(0)\n",
    "        \n",
    "        cand_1gram, cand_2gram, cand_3gram, cand_4gram = _get_ngram_sets(candidate_summary)\n",
    "        \n",
    "        rouge_recall_1 = 0\n",
    "        if len(gold_1gram) != 0:\n",
    "            rouge_recall_1 = float(len(gold_1gram.intersection(cand_1gram)))/float(len(gold_1gram))\n",
    "            \n",
    "        rouge_precision_1 = 0\n",
    "        if len(cand_1gram) != 0:\n",
    "            rouge_precision_1 = float(len(gold_1gram.intersection(cand_1gram)))/float(len(cand_1gram))\n",
    "            \n",
    "        rouge_f1_1 = 2 * rouge_recall_1 * rouge_precision_1 / (rouge_recall_1 + rouge_precision_1 + 10e-10)\n",
    "        \n",
    "        rouge_recall_2 = 0\n",
    "        if len(gold_2gram) != 0:\n",
    "            rouge_recall_2 = float(len(gold_2gram.intersection(cand_2gram)))/float(len(gold_2gram))\n",
    "        \n",
    "        rouge_precision_2 = 0\n",
    "        if len(cand_2gram) != 0:\n",
    "            rouge_precision_2 = float(len(gold_2gram.intersection(cand_2gram)))/float(len(cand_2gram))\n",
    "\n",
    "        rouge_f1_2 = 2 * rouge_recall_2 * rouge_precision_2 / (rouge_recall_2 + rouge_precision_2 + 10e-10)\n",
    "        \n",
    "        len_lcs = _get_lcs(line, gold)\n",
    "        r = 0 if (len_lcs == 0) else (float(len_lcs)/len(line))\n",
    "        p = 0 if (len_lcs == 0) else (float(len_lcs)/len(gold))\n",
    "        b = 0 if (r == 0) else (p / r)\n",
    "        rouge_recall_l = 0 if (len_lcs == 0) else (((1+(b*b))*r*p)/(r+(b*b*p)))\n",
    "        \n",
    "        rouge_f1_l = 2 * r * p / (r + p + 10e-10)\n",
    "        \n",
    "        rouge_recall_average = (rouge_recall_1+rouge_recall_2+rouge_recall_l)/3.0\n",
    "        rouge_f1_avg = (rouge_f1_1 + rouge_f1_2 + rouge_f1_l)/3.0\n",
    "        if f1: scores.append(rouge_f1_avg)\n",
    "        else: scores.append(rouge_recall_average)\n",
    "\n",
    "    sorted_indices = sorted(enumerate(scores), key=lambda x: x[1], reverse=True)[0:max_sum_select]\n",
    "    selected_indices, scores = list(zip(*sorted_indices))\n",
    "    selected_candidates = [candidates[i] for i in selected_indices]\n",
    "    \n",
    "    selected_summaries = [[lines_selected[i] for i in indices] for indices in selected_candidates]\n",
    "\n",
    "    return list(zip(selected_summaries, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_summaries_folder(doc_folder, sum_folder, max_sum_len=4, \n",
    "                                max_sum_select=15, f1=True, dump_file=None):\n",
    "    '''\n",
    "    calls get_top_k_sentences and get_candidate_summaries for \n",
    "    each document in doc_folder.\n",
    "    '''\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    max_len = 10\n",
    "\n",
    "    combinations = [[None for _ in range(max_sum_len+1)] for _ in range(max_len+1)]\n",
    "    for i in range(max_len+1):\n",
    "        for j in range(max_sum_len+1):\n",
    "            combinations[i][j] = list(itertools.combinations(range(i), j))\n",
    "\n",
    "    files = sorted(os.listdir(doc_folder), key=lambda x: int(x))\n",
    "    for file in files:\n",
    "        with open(os.path.join(doc_folder, file)) as f:\n",
    "            document = [[a.lower() for a in line.split(' ')] for line in f.read().split('\\n')]\n",
    "        with open(os.path.join(sum_folder, file)) as f:\n",
    "            summary =  [[a.lower() for a in line.split(' ')] for line in f.read().split('\\n')]\n",
    "        \n",
    "        print(file, ' '*10, end='\\r')\n",
    "            \n",
    "        scores.append(get_candidate_summaries(combinations, document, summary, \n",
    "                                              get_top_k_sentences(document, summary, 10), \n",
    "                                            3, 10))\n",
    "    \n",
    "    if dump_file:\n",
    "        pickle.dump(scores, open(dump_file, 'wb+'))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
